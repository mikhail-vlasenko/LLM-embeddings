{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBD6E2i__bp3",
        "outputId": "e9e0071a-3f6b-4001-ec95-c169edbdc22e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install seacrowd>=0.2.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E2TFoS5OZMdZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VqoIDhfU-iPl"
      },
      "outputs": [],
      "source": [
        "class FloresMultiLangDataset(Dataset):\n",
        "    def __init__(self, dataset, languages, tokenizer, max_length=512):\n",
        "        \"\"\"\n",
        "        Custom PyTorch Dataset to load multiple languages from FLORES-200.\n",
        "        Args:\n",
        "            dataset (datasets.Dataset): The loaded dataset from FLORES-200.\n",
        "            languages (dict): Dictionary of language names and their codes (e.g., {'English': 'eng_Latn', ...}).\n",
        "            tokenizer (AutoTokenizer): The tokenizer for encoding text.\n",
        "            max_length (int): Maximum sequence length for tokenization.\n",
        "        \"\"\"\n",
        "        self.dataset = dataset\n",
        "        self.languages = languages\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentences = {}\n",
        "        for lang_name, lang_code in self.languages.items():\n",
        "            sentence = self.dataset[idx][f\"sentence_{lang_code}\"]\n",
        "            sentences[lang_name] = sentence\n",
        "\n",
        "            # # Tokenize the sentence\n",
        "            # tokenized_input = self.tokenizer(\n",
        "            #     template.format(sentence=sentence),\n",
        "            #     return_tensors='pt',\n",
        "            #     padding=True,\n",
        "            #     truncation=True,\n",
        "            #     max_length=self.max_length\n",
        "            # )\n",
        "            # tokenized_input = {k: v.to(device) for k, v in tokenized_input.items()}\n",
        "            # sentences[f\"{lang_name}_inputs\"] = tokenized_input\n",
        "\n",
        "        return sentences\n",
        "\n",
        "\n",
        "\n",
        "def compare_languages(embeddings_dict, languages):\n",
        "    \"\"\"\n",
        "    Compare each language embedding with every other language embedding and print cosine similarity scores.\n",
        "    Args:\n",
        "        embeddings_dict (dict): Dictionary of embeddings for each language.\n",
        "        languages (dict): Dictionary of language names and codes.\n",
        "    \"\"\"\n",
        "    lang_names = list(languages.keys())\n",
        "    for i, lang1 in enumerate(lang_names):\n",
        "        for lang2 in lang_names[i + 1:]:\n",
        "            sim_score = cosine_similarity(embeddings_dict[lang1], embeddings_dict[lang2])\n",
        "            print(f\"Similarity between {lang1} and {lang2}: {sim_score[0][0]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tVgqSHP_FJZQ"
      },
      "outputs": [],
      "source": [
        "class FloresMultiLangDataset_embed(Dataset):\n",
        "    def __init__(self, dataset, languages, tokenizer, max_length=512):\n",
        "        \"\"\"\n",
        "        Custom PyTorch Dataset to load multiple languages from FLORES-200.\n",
        "        Args:\n",
        "            dataset (datasets.Dataset): The loaded dataset from FLORES-200.\n",
        "            languages (dict): Dictionary of language names and their codes (e.g., {'English': 'eng_Latn', ...}).\n",
        "            tokenizer (AutoTokenizer): The tokenizer for encoding text.\n",
        "            max_length (int): Maximum sequence length for tokenization.\n",
        "        \"\"\"\n",
        "        self.dataset = dataset\n",
        "        self.languages = languages\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentences = {}\n",
        "        for lang_name, lang_code in self.languages.items():\n",
        "            sentence = self.dataset[idx][f\"sentence_{lang_code}\"]\n",
        "            sentences[lang_name] = sentence\n",
        "\n",
        "            # Tokenize the sentence\n",
        "            tokenized_input = self.tokenizer(\n",
        "                template.format(sentence=sentence),\n",
        "                return_tensors='pt',\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=self.max_length\n",
        "            )\n",
        "            tokenized_input = {k: v.to(device) for k, v in tokenized_input.items()}\n",
        "            sentences[f\"{lang_name}_inputs\"] = tokenized_input\n",
        "\n",
        "        return sentences\n",
        "\n",
        "\n",
        "\n",
        "def compare_languages(embeddings_dict, languages):\n",
        "    \"\"\"\n",
        "    Compare each language embedding with every other language embedding and print cosine similarity scores.\n",
        "    Args:\n",
        "        embeddings_dict (dict): Dictionary of embeddings for each language.\n",
        "        languages (dict): Dictionary of language names and codes.\n",
        "    \"\"\"\n",
        "    lang_names = list(languages.keys())\n",
        "    for i, lang1 in enumerate(lang_names):\n",
        "        for lang2 in lang_names[i + 1:]:\n",
        "            sim_score = cosine_similarity(embeddings_dict[lang1], embeddings_dict[lang2])\n",
        "            print(f\"Similarity between {lang1} and {lang2}: {sim_score[0][0]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CEIy1BN5Ih_Y"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Custom collate function for padding the inputs in a batch and including the actual sentences.\n",
        "    \"\"\"\n",
        "    batch_dict = {}\n",
        "\n",
        "    for lang_name in languages.keys():\n",
        "        # Extract all the tokenized inputs, attention masks, and actual sentences for this language in the batch\n",
        "        inputs = [item[f\"{lang_name}_inputs\"]['input_ids'].squeeze(0) for item in batch]\n",
        "        attention_masks = [item[f\"{lang_name}_inputs\"]['attention_mask'].squeeze(0) for item in batch]\n",
        "        sentences = [item[lang_name] for item in batch]  # Actual sentences\n",
        "\n",
        "        # Pad the sequences for each language\n",
        "        padded_inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "        padded_masks = torch.nn.utils.rnn.pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
        "\n",
        "        # Store padded inputs, masks, and sentences\n",
        "        batch_dict[f\"{lang_name}_inputs\"] = {\n",
        "            'input_ids': padded_inputs,\n",
        "            'attention_mask': padded_masks\n",
        "        }\n",
        "        # batch_dict[f\"{lang_name}_attention_masks\"] = padded_masks\n",
        "        batch_dict[f\"{lang_name}\"] = sentences\n",
        "\n",
        "    return batch_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GI71y3JERglN"
      },
      "outputs": [],
      "source": [
        "def get_embeddings_orginal(model, inputs, tokenizer, device,avg_pooling=False):\n",
        "    embeddings = []\n",
        "    for input in inputs:\n",
        "        # Tokenize the sentence\n",
        "        tokenized_input = tokenizer(\n",
        "                template.format(sentence=input),\n",
        "                return_tensors='pt',\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=512\n",
        "        )\n",
        "        input = {k: v.to(device) for k, v in tokenized_input.items()}\n",
        "        # Get raw embeddings\n",
        "        with torch.no_grad():\n",
        "            # print(input)\n",
        "            hidden_states = model(output_hidden_states=True, return_dict=True, **input).hidden_states\n",
        "            if avg_pooling:\n",
        "                last_layer = hidden_states[-1]\n",
        "                attention_mask = input['attention_mask'].unsqueeze(-1).expand(last_layer.shape)\n",
        "                outputs = (last_layer * attention_mask).mean(1)\n",
        "            else:\n",
        "                outputs = hidden_states[-1][:, -1, :]\n",
        "\n",
        "            if outputs.dtype == torch.bfloat16:\n",
        "                # bfloat16 not support for .numpy()\n",
        "                outputs = outputs.float()\n",
        "\n",
        "            embeddings.append(outputs.cpu().numpy())\n",
        "\n",
        "    return np.vstack(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bp6Fk5bUTigN"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(model, tokenizer, sentences, device, target_language,avg_pooling=True):\n",
        "    embeddings = []\n",
        "    for sentence in sentences:\n",
        "        sentence = template[target_language].format(sentence=sentence)\n",
        "        inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Get raw embeddings\n",
        "        with torch.no_grad():\n",
        "            hidden_states = model(output_hidden_states=True, return_dict=True, **inputs).hidden_states\n",
        "            if avg_pooling:\n",
        "                last_layer = hidden_states[-1]\n",
        "                attention_mask = inputs['attention_mask'].unsqueeze(-1).expand(last_layer.shape)\n",
        "                outputs = (last_layer * attention_mask).mean(1)\n",
        "            else:\n",
        "                outputs = hidden_states[-1][:, -1, :]\n",
        "\n",
        "            if outputs.dtype == torch.bfloat16:\n",
        "                outputs = outputs.float()\n",
        "\n",
        "            embeddings.append(outputs.cpu().numpy())\n",
        "\n",
        "    return np.vstack(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nh47oiNrS3Yy"
      },
      "outputs": [],
      "source": [
        "def find_most_similar(query_embedding, target_embeddings):\n",
        "    similarities = cosine_similarity(query_embedding.reshape(1, -1), target_embeddings)[0]\n",
        "    return np.argmax(similarities)\n",
        "\n",
        "def compare_languages(embeddings_dict, languages):\n",
        "    \"\"\"\n",
        "    Compare each language embedding with every other language embedding.\n",
        "    Args:\n",
        "        embeddings_dict (dict): Dictionary of embeddings for each language.\n",
        "        languages (dict): Dictionary of language names and codes.\n",
        "\n",
        "    Returns:\n",
        "        list of dict: List containing cosine similarity scores between languages.\n",
        "    \"\"\"\n",
        "    lang_names = list(languages.keys())\n",
        "    results = []\n",
        "\n",
        "    for i, lang1 in enumerate(lang_names):\n",
        "        for lang2 in lang_names[i + 1:]:\n",
        "            # sim_score = cosine_similarity(embeddings_dict[lang1], embeddings_dict[lang2])\n",
        "            sim_score = find_most_similar(embeddings_dict[lang1], embeddings_dict[lang2])\n",
        "            print(\"sim_score\", sim_score)\n",
        "            avg_score = sim_score  # Assuming the similarity score is a 2D array\n",
        "            results.append({'Language 1': lang1, 'Language 2': lang2, 'Cosine Similarity': avg_score})\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KKTDwQhDil7s"
      },
      "outputs": [],
      "source": [
        "def save_embeddings(embeddings_dict, filename):\n",
        "    # Get all the unique \"target_language-language\" pairs as columns\n",
        "    columns = []\n",
        "    for target_language in embeddings_dict:\n",
        "        for language in embeddings_dict[target_language]:\n",
        "            column_name = f\"{target_language}-{language}\"\n",
        "            columns.append(column_name)\n",
        "\n",
        "    # Assuming all embeddings have the same index length\n",
        "    index_length = len(next(iter(next(iter(embeddings_dict.values())).values())))\n",
        "    # Prepare the data to be written to CSV\n",
        "    data = []\n",
        "    for i in range(index_length):\n",
        "        row = []\n",
        "        for target_language in embeddings_dict:\n",
        "            for language in embeddings_dict[target_language]:\n",
        "                embedding = embeddings_dict[target_language][language][i]\n",
        "                row.append(embedding)\n",
        "        data.append(row)\n",
        "\n",
        "    # Write to CSV\n",
        "    with open(filename, 'w', newline='') as csvfile:\n",
        "        csvwriter = csv.writer(csvfile)\n",
        "\n",
        "        # Write the header (columns)\n",
        "        csvwriter.writerow(columns)\n",
        "\n",
        "        # Write the data (rows)\n",
        "        csvwriter.writerows(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3ndce6h6E7hn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Function to normalize embeddings\n",
        "def normalize_embeddings(embeddings):\n",
        "    return (embeddings.T / np.linalg.norm(embeddings, axis=1)).T\n",
        "\n",
        "# Function to compute cosine similarity between embeddings\n",
        "def compute_similarity(embedding, embeddings_to_compare):\n",
        "    return embedding @ embeddings_to_compare.T\n",
        "\n",
        "# Function for recall@1\n",
        "def recall_at_1(similarity, targets):\n",
        "    similarity = np.argsort(similarity, axis=1)[:, ::-1]\n",
        "    correct = 0\n",
        "    for i in range(similarity.shape[0]):\n",
        "        if targets[i] == similarity[i, 0]:\n",
        "            correct += 1\n",
        "    recall_at_1 = correct / similarity.shape[0]\n",
        "    return recall_at_1\n",
        "\n",
        "# Function for recall@k\n",
        "def recall_at_k(similarity, targets, k=3):\n",
        "    similarity = np.argsort(similarity, axis=1)[:, ::-1]\n",
        "    correct = 0\n",
        "    for i in range(similarity.shape[0]):\n",
        "        if targets[i] in similarity[i, :k]:\n",
        "            correct += 1\n",
        "    recall_at_k = correct / similarity.shape[0]\n",
        "    return recall_at_k\n",
        "\n",
        "# Updated function to evaluate translation accuracy and save average recall\n",
        "def evaluate_translation_accuracy(embeddings_dict, target_language, k=3):\n",
        "    total_recall_1_per_language = {lang: 0 for lang in embeddings_dict if lang != target_language}\n",
        "    total_recall_k_per_language = {lang: 0 for lang in embeddings_dict if lang != target_language}\n",
        "    total_pairs = len(embeddings_dict[target_language])  # Assuming target language is the reference\n",
        "\n",
        "    # Target array, where each sentence in the target language should map to its corresponding index in each other language\n",
        "    targets = list(range(total_pairs))\n",
        "\n",
        "    print(\"\\nEvaluating translation accuracy using recall@k...\")\n",
        "\n",
        "    # Loop through each sentence embedding in the target language\n",
        "    for i, target_embedding in enumerate(embeddings_dict[target_language]):\n",
        "\n",
        "        for lang_name, lang_embeddings in embeddings_dict.items():\n",
        "            if lang_name == target_language:\n",
        "                continue  # Skip comparing the target language with itself\n",
        "\n",
        "            # Compute similarity between the current target sentence embedding and all sentence embeddings in the other language\n",
        "            similarity = compute_similarity(target_embedding.reshape(1, -1), lang_embeddings)\n",
        "\n",
        "            # Calculate recall@1 and recall@k for this specific sentence\n",
        "            recall_1 = recall_at_1(similarity, [i])  # i is the target index for the corresponding sentence\n",
        "            recall_k = recall_at_k(similarity, [i], k=k)\n",
        "\n",
        "            # Accumulate total recall values for each language\n",
        "            total_recall_1_per_language[lang_name] += recall_1\n",
        "            total_recall_k_per_language[lang_name] += recall_k\n",
        "\n",
        "    # Calculate average recall@1 and recall@k for each language\n",
        "    avg_recall_1_per_language = {lang: total_recall_1_per_language[lang] / total_pairs for lang in total_recall_1_per_language}\n",
        "    avg_recall_k_per_language = {lang: total_recall_k_per_language[lang] / total_pairs for lang in total_recall_k_per_language}\n",
        "\n",
        "    # Save the average recall scores into a table\n",
        "    results_table = []\n",
        "    for lang_name in avg_recall_1_per_language:\n",
        "        results_table.append({\n",
        "            'Target Language': target_language,\n",
        "            'Compared Language': lang_name,\n",
        "            'Avg Recall@1': avg_recall_1_per_language[lang_name],\n",
        "            'Avg Recall@k': avg_recall_k_per_language[lang_name]\n",
        "        })\n",
        "\n",
        "    # Convert the results to a DataFrame\n",
        "    results_df = pd.DataFrame(results_table)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    results_df.to_csv('f{}average_translation_accuracy_results.csv', index=False)\n",
        "\n",
        "    print(\"\\nAverage recall results saved to average_translation_accuracy_results.csv\")\n",
        "    print(results_df)\n",
        "    return results_table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAkCtWINhanu"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rmu39R4ftCzW"
      },
      "outputs": [],
      "source": [
        "# Define the sentence template for each language\n",
        "template = {\n",
        "    'English': 'This sentence: \"{sentence}\" means in one word:',\n",
        "    'Chinese_Simplified': '这句话: \"{sentence}\" 用一个词来表示是:',\n",
        "    'Russian': 'Это предложение: \"{sentence}\" означает одним словом:',\n",
        "    'Dutch': 'Deze zin: \"{sentence}\" betekent in één woord:',\n",
        "    'German': 'Dieser Satz: \"{sentence}\" bedeutet mit einem Wort:'\n",
        "}\n",
        "\n",
        "# Language dictionary mapping language names to their FLORES-200 codes\n",
        "languages = {\n",
        "    'English': 'eng_Latn',\n",
        "    'Chinese_Simplified': 'zho_Hans',\n",
        "    'Russian': 'rus_Cyrl',\n",
        "    'Dutch': 'nld_Latn',\n",
        "    'German': 'deu_Latn'\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294,
          "referenced_widgets": [
            "0916ed70905444dab15c76ac5d74328c",
            "d1b42a340f4c4303bc347ee9ee7d2e81",
            "cc18fbf83bf240fa851fd2a291666768",
            "96a1bfd5356d475ca1c274fd715d3437",
            "474e4c430c4d44e7adc7f230947f318a",
            "dd4ffbe076364c7ca5f6fa68396c62ca",
            "82f3efc0497c446499fc2ec7419354bc",
            "daab73cd4cd44e8f853567b3adedc650",
            "9a906965159b4ed7ac595072b0caab13",
            "a70458a664b245668b715989df7c8d82",
            "25bc8469c13148b0bf185adcd54b3b33",
            "a4b01774deb2484297e1757add9f06bb",
            "e643706dbdc54dda9b5111d3a6aa528e",
            "2b744becc9214cbd9b80da13425d8d8c",
            "b35ff16065664cd48fd83966815f4f56",
            "434b438213db4adba9bd70346427b991",
            "f250c285be314b09aafee4a283db20d0",
            "c8d181548f9c42f895ddc4d1c578b9ca",
            "c2392dabea4648e4bfd44675ae1b3822",
            "b808f34b5d054f1fbce82a6d7df9bd5e",
            "7cfb96d6f9824f798c031cd64d6f7e63",
            "fb706afa53924116854c9d168a58a219",
            "1727238b51c54866bf2bd3c1b5e1ec4c",
            "27cbe9eb0c434cfe9c550c7b96b127cf",
            "f405cb8ee1f94e2a8a5e7135bef3b3ae",
            "f28e5438dbed4145b91e691469d71a32",
            "97a7a1eb78524f709813baaeba2fce4d",
            "381ac6dd0c264083a1f5e518d55a6d1f",
            "2b3535b452de4af39eaba783f918968d",
            "08434042c698451fa8d42152c5ecae11",
            "2fe92f6a73f649a2a92a5b4471ed1789",
            "5da45cbd6f2c4c2aa762ccf5fb974d42",
            "cee50c512a2646d2b0edce71af9ff905"
          ]
        },
        "id": "-6r7vDEZiznj",
        "outputId": "6258b16c-cecc-4d05-9a4b-2af199843212"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0916ed70905444dab15c76ac5d74328c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
            "- configuration_phi3.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4b01774deb2484297e1757add9f06bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
            "- modeling_phi3.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1727238b51c54866bf2bd3c1b5e1ec4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\",\n",
        "                                                     device_map='auto',\n",
        "                                                     output_hidden_states=True,\n",
        "                                                     trust_remote_code=True,\n",
        "                                                     load_in_8bit= 16 == 8)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
        "tokenizer.pad_token_id = 0  # unk. we want this to be different from the eos token\n",
        "tokenizer.padding_side = \"left\"  # Allow batched inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgQ4KPvYkRwJ",
        "outputId": "2d0f05fd-56a4-4adb-b8e8-33340e881764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "# Load FLORES-200 dataset\n",
        "dataset = load_dataset('Muennighoff/flores200', 'all', split='devtest',trust_remote_code=True)\n",
        "max_samples = 4\n",
        "if max_samples:\n",
        "    dataset = dataset.select(range(max_samples))\n",
        "\n",
        "flores_dataset = FloresMultiLangDataset(dataset, languages, tokenizer)\n",
        "\n",
        "data_loader = DataLoader(flores_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "\n",
        "print(len(flores_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qjRNBPfkKBm",
        "outputId": "b61cd6a1-6805-49e6-9f4e-2e6e6b4659c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embeddings for all languages...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rBatches Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating embeddings for target language: English and langauge English\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating embeddings for target language: English and langauge Chinese_Simplified\n",
            "\n",
            "Generating embeddings for target language: English and langauge Russian\n",
            "\n",
            "Generating embeddings for target language: English and langauge Dutch\n",
            "\n",
            "Generating embeddings for target language: English and langauge German\n",
            "\n",
            "Generating embeddings for target language: Chinese_Simplified and langauge English\n",
            "\n",
            "Generating embeddings for target language: Chinese_Simplified and langauge Chinese_Simplified\n",
            "\n",
            "Generating embeddings for target language: Chinese_Simplified and langauge Russian\n",
            "\n",
            "Generating embeddings for target language: Chinese_Simplified and langauge Dutch\n",
            "\n",
            "Generating embeddings for target language: Chinese_Simplified and langauge German\n",
            "\n",
            "Generating embeddings for target language: Russian and langauge English\n",
            "\n",
            "Generating embeddings for target language: Russian and langauge Chinese_Simplified\n",
            "\n",
            "Generating embeddings for target language: Russian and langauge Russian\n",
            "\n",
            "Generating embeddings for target language: Russian and langauge Dutch\n",
            "\n",
            "Generating embeddings for target language: Russian and langauge German\n",
            "\n",
            "Generating embeddings for target language: Dutch and langauge English\n",
            "\n",
            "Generating embeddings for target language: Dutch and langauge Chinese_Simplified\n",
            "\n",
            "Generating embeddings for target language: Dutch and langauge Russian\n",
            "\n",
            "Generating embeddings for target language: Dutch and langauge Dutch\n",
            "\n",
            "Generating embeddings for target language: Dutch and langauge German\n",
            "\n",
            "Generating embeddings for target language: German and langauge English\n",
            "\n",
            "Generating embeddings for target language: German and langauge Chinese_Simplified\n",
            "\n",
            "Generating embeddings for target language: German and langauge Russian\n",
            "\n",
            "Generating embeddings for target language: German and langauge Dutch\n",
            "\n",
            "Generating embeddings for target language: German and langauge German\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rBatches Progress:  50%|█████     | 1/2 [00:42<00:42, 42.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating embeddings for target language: English and langauge English\n",
            "\n",
            "Generating embeddings for target language: English and langauge Chinese_Simplified\n",
            "\n",
            "Generating embeddings for target language: English and langauge Russian\n",
            "\n",
            "Generating embeddings for target language: English and langauge Dutch\n",
            "\n",
            "Generating embeddings for target language: English and langauge German\n",
            "\n",
            "Generating embeddings for target language: Chinese_Simplified and langauge English\n",
            "\n",
            "Generating embeddings for target language: Chinese_Simplified and langauge Chinese_Simplified\n",
            "\n",
            "Generating embeddings for target language: Chinese_Simplified and langauge Russian\n",
            "\n",
            "Generating embeddings for target language: Chinese_Simplified and langauge Dutch\n",
            "\n",
            "Generating embeddings for target language: Chinese_Simplified and langauge German\n",
            "\n",
            "Generating embeddings for target language: Russian and langauge English\n",
            "\n",
            "Generating embeddings for target language: Russian and langauge Chinese_Simplified\n",
            "\n",
            "Generating embeddings for target language: Russian and langauge Russian\n",
            "\n",
            "Generating embeddings for target language: Russian and langauge Dutch\n",
            "\n",
            "Generating embeddings for target language: Russian and langauge German\n",
            "\n",
            "Generating embeddings for target language: Dutch and langauge English\n",
            "\n",
            "Generating embeddings for target language: Dutch and langauge Chinese_Simplified\n",
            "\n",
            "Generating embeddings for target language: Dutch and langauge Russian\n",
            "\n",
            "Generating embeddings for target language: Dutch and langauge Dutch\n",
            "\n",
            "Generating embeddings for target language: Dutch and langauge German\n",
            "\n",
            "Generating embeddings for target language: German and langauge English\n",
            "\n",
            "Generating embeddings for target language: German and langauge Chinese_Simplified\n",
            "\n",
            "Generating embeddings for target language: German and langauge Russian\n",
            "\n",
            "Generating embeddings for target language: German and langauge Dutch\n",
            "\n",
            "Generating embeddings for target language: German and langauge German\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches Progress: 100%|██████████| 2/2 [01:18<00:00, 39.33s/it]\n"
          ]
        }
      ],
      "source": [
        "# Initialize dictionary to store embeddings for each target language and language pair\n",
        "embeddings_dict = {target_language: {lang_name: np.array([]) for lang_name in languages.keys()} for target_language in languages.keys()}\n",
        "\n",
        "# Stage 1: Save embeddings for each language and target language\n",
        "print(\"Generating embeddings for all languages...\")\n",
        "\n",
        "# Iterate through batches and generate embeddings\n",
        "for batch in tqdm(data_loader, desc=\"Batches Progress\", leave=True):\n",
        "    for target_language in languages.keys():\n",
        "\n",
        "        for lang_name in languages.keys():\n",
        "            print(f\"\\nGenerating embeddings for target language: {target_language} and langauge {lang_name}\")\n",
        "            # Get embeddings for the current language and append to the dictionary for the target language\n",
        "            inputs = batch[f\"{lang_name}\"]\n",
        "            embeddings = get_embeddings(model, tokenizer, inputs, device, target_language)\n",
        "\n",
        "            # Convert list to a NumPy array and append to the dictionary for the target language\n",
        "            if len(embeddings_dict[target_language][lang_name]) == 0:\n",
        "\n",
        "                # If it's the first batch, initialize the array\n",
        "                embeddings_dict[target_language][lang_name] = embeddings\n",
        "\n",
        "            else:\n",
        "                # Concatenate the new embeddings with the existing array\n",
        "                embeddings_dict[target_language][lang_name] = np.concatenate(\n",
        "                    (embeddings_dict[target_language][lang_name], embeddings),\n",
        "                    axis=0\n",
        "                )\n",
        "\n",
        "# At this point, embeddings_dict contains embeddings for all languages and target languages\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW0Uwp-em0Fk",
        "outputId": "e0e47c1e-b842-4fb8-8909-80922b1e822a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating translation accuracy for each target language...\n",
            "\n",
            "Evaluating target language: English\n",
            "\n",
            "Evaluating translation accuracy using recall@k...\n",
            "\n",
            "Average recall results saved to average_translation_accuracy_results.csv\n",
            "  Target Language   Compared Language  Avg Recall@1  Avg Recall@k\n",
            "0         English  Chinese_Simplified          0.25          0.75\n",
            "1         English             Russian          0.25          1.00\n",
            "2         English               Dutch          0.25          0.75\n",
            "3         English              German          0.25          0.75\n",
            "\n",
            "Evaluating target language: Chinese_Simplified\n",
            "\n",
            "Evaluating translation accuracy using recall@k...\n",
            "\n",
            "Average recall results saved to average_translation_accuracy_results.csv\n",
            "      Target Language Compared Language  Avg Recall@1  Avg Recall@k\n",
            "0  Chinese_Simplified           English          0.25          0.75\n",
            "1  Chinese_Simplified           Russian          0.25          0.75\n",
            "2  Chinese_Simplified             Dutch          0.25          0.75\n",
            "3  Chinese_Simplified            German          0.25          0.75\n",
            "\n",
            "Evaluating target language: Russian\n",
            "\n",
            "Evaluating translation accuracy using recall@k...\n",
            "\n",
            "Average recall results saved to average_translation_accuracy_results.csv\n",
            "  Target Language   Compared Language  Avg Recall@1  Avg Recall@k\n",
            "0         Russian             English          0.25          0.75\n",
            "1         Russian  Chinese_Simplified          0.25          0.75\n",
            "2         Russian               Dutch          0.25          1.00\n",
            "3         Russian              German          0.25          0.75\n",
            "\n",
            "Evaluating target language: Dutch\n",
            "\n",
            "Evaluating translation accuracy using recall@k...\n",
            "\n",
            "Average recall results saved to average_translation_accuracy_results.csv\n",
            "  Target Language   Compared Language  Avg Recall@1  Avg Recall@k\n",
            "0           Dutch             English          0.25          0.75\n",
            "1           Dutch  Chinese_Simplified          0.25          0.75\n",
            "2           Dutch             Russian          0.25          1.00\n",
            "3           Dutch              German          0.25          0.75\n",
            "\n",
            "Evaluating target language: German\n",
            "\n",
            "Evaluating translation accuracy using recall@k...\n",
            "\n",
            "Average recall results saved to average_translation_accuracy_results.csv\n",
            "  Target Language   Compared Language  Avg Recall@1  Avg Recall@k\n",
            "0          German             English          0.25          1.00\n",
            "1          German  Chinese_Simplified          0.25          0.75\n",
            "2          German             Russian          0.25          0.75\n",
            "3          German               Dutch          0.50          0.75\n",
            "\n",
            "Final Results:\n",
            "[{'Target Language': 'English', 'Compared Language': 'Chinese_Simplified', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'English', 'Compared Language': 'Russian', 'Avg Recall@1': 0.25, 'Avg Recall@k': 1.0}, {'Target Language': 'English', 'Compared Language': 'Dutch', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'English', 'Compared Language': 'German', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'Chinese_Simplified', 'Compared Language': 'English', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'Chinese_Simplified', 'Compared Language': 'Russian', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'Chinese_Simplified', 'Compared Language': 'Dutch', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'Chinese_Simplified', 'Compared Language': 'German', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'Russian', 'Compared Language': 'English', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'Russian', 'Compared Language': 'Chinese_Simplified', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'Russian', 'Compared Language': 'Dutch', 'Avg Recall@1': 0.25, 'Avg Recall@k': 1.0}, {'Target Language': 'Russian', 'Compared Language': 'German', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'Dutch', 'Compared Language': 'English', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'Dutch', 'Compared Language': 'Chinese_Simplified', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'Dutch', 'Compared Language': 'Russian', 'Avg Recall@1': 0.25, 'Avg Recall@k': 1.0}, {'Target Language': 'Dutch', 'Compared Language': 'German', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'German', 'Compared Language': 'English', 'Avg Recall@1': 0.25, 'Avg Recall@k': 1.0}, {'Target Language': 'German', 'Compared Language': 'Chinese_Simplified', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'German', 'Compared Language': 'Russian', 'Avg Recall@1': 0.25, 'Avg Recall@k': 0.75}, {'Target Language': 'German', 'Compared Language': 'Dutch', 'Avg Recall@1': 0.5, 'Avg Recall@k': 0.75}]\n"
          ]
        }
      ],
      "source": [
        "# Stage 2: Evaluate translation accuracy using the stored embeddings\n",
        "print(\"Evaluating translation accuracy for each target language...\")\n",
        "\n",
        "# Initialize list to store results\n",
        "all_results = []\n",
        "\n",
        "# this is the prompt\n",
        "for target_language in languages.keys():\n",
        "    print(f\"\\nEvaluating target language: {target_language}\")\n",
        "\n",
        "    # Evaluate using the embeddings in the dictionary for current target language vs. other languages\n",
        "    results_table = evaluate_translation_accuracy(embeddings_dict[target_language], target_language, k=3)\n",
        "\n",
        "    # Store the results for each comparison\n",
        "    all_results += results_table\n",
        "\n",
        "# Print a summary of the results\n",
        "print(\"\\nFinal Results:\")\n",
        "print(all_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtPb-TqyA_1A",
        "outputId": "035814df-9379-48bc-d1f8-17ece429f526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compared Language   Chinese_Simplified  Dutch  English  German  Russian\n",
            "Target Language                                                        \n",
            "Chinese_Simplified                 NaN   0.75     0.75    0.75     0.75\n",
            "Dutch                             0.75    NaN     0.75    0.75     1.00\n",
            "English                           0.75   0.75      NaN    0.75     1.00\n",
            "German                            0.75   0.75     1.00     NaN     0.75\n",
            "Russian                           0.75   1.00     0.75    0.75      NaN\n"
          ]
        }
      ],
      "source": [
        "# Convert the list to a DataFrame\n",
        "df = pd.DataFrame(all_results)\n",
        "df.to_csv('average_translation_accuracy_results.csv', index=False)\n",
        "\n",
        "# Dynamically pivot the DataFrame based on target and compared languages\n",
        "\n",
        "pivot_df = df.pivot(index='Target Language', columns='Compared Language', values='Avg Recall@k')\n",
        "\n",
        "pivot_df.to_csv('average_translation_accuracy_table.csv', index=True)\n",
        "\n",
        "# Show the result\n",
        "print(pivot_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hc2Acf5bOTOJ"
      },
      "outputs": [],
      "source": [
        "save_embeddings(embeddings_dict, 'embeddings.csv')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08434042c698451fa8d42152c5ecae11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0916ed70905444dab15c76ac5d74328c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1b42a340f4c4303bc347ee9ee7d2e81",
              "IPY_MODEL_cc18fbf83bf240fa851fd2a291666768",
              "IPY_MODEL_96a1bfd5356d475ca1c274fd715d3437"
            ],
            "layout": "IPY_MODEL_474e4c430c4d44e7adc7f230947f318a"
          }
        },
        "1727238b51c54866bf2bd3c1b5e1ec4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27cbe9eb0c434cfe9c550c7b96b127cf",
              "IPY_MODEL_f405cb8ee1f94e2a8a5e7135bef3b3ae",
              "IPY_MODEL_f28e5438dbed4145b91e691469d71a32"
            ],
            "layout": "IPY_MODEL_97a7a1eb78524f709813baaeba2fce4d"
          }
        },
        "25bc8469c13148b0bf185adcd54b3b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27cbe9eb0c434cfe9c550c7b96b127cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_381ac6dd0c264083a1f5e518d55a6d1f",
            "placeholder": "​",
            "style": "IPY_MODEL_2b3535b452de4af39eaba783f918968d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2b3535b452de4af39eaba783f918968d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b744becc9214cbd9b80da13425d8d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2392dabea4648e4bfd44675ae1b3822",
            "max": 73814,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b808f34b5d054f1fbce82a6d7df9bd5e",
            "value": 73814
          }
        },
        "2fe92f6a73f649a2a92a5b4471ed1789": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "381ac6dd0c264083a1f5e518d55a6d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "434b438213db4adba9bd70346427b991": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474e4c430c4d44e7adc7f230947f318a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5da45cbd6f2c4c2aa762ccf5fb974d42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cfb96d6f9824f798c031cd64d6f7e63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82f3efc0497c446499fc2ec7419354bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96a1bfd5356d475ca1c274fd715d3437": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a70458a664b245668b715989df7c8d82",
            "placeholder": "​",
            "style": "IPY_MODEL_25bc8469c13148b0bf185adcd54b3b33",
            "value": " 11.2k/11.2k [00:00&lt;00:00, 943kB/s]"
          }
        },
        "97a7a1eb78524f709813baaeba2fce4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a906965159b4ed7ac595072b0caab13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4b01774deb2484297e1757add9f06bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e643706dbdc54dda9b5111d3a6aa528e",
              "IPY_MODEL_2b744becc9214cbd9b80da13425d8d8c",
              "IPY_MODEL_b35ff16065664cd48fd83966815f4f56"
            ],
            "layout": "IPY_MODEL_434b438213db4adba9bd70346427b991"
          }
        },
        "a70458a664b245668b715989df7c8d82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b35ff16065664cd48fd83966815f4f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cfb96d6f9824f798c031cd64d6f7e63",
            "placeholder": "​",
            "style": "IPY_MODEL_fb706afa53924116854c9d168a58a219",
            "value": " 73.8k/73.8k [00:00&lt;00:00, 4.20MB/s]"
          }
        },
        "b808f34b5d054f1fbce82a6d7df9bd5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2392dabea4648e4bfd44675ae1b3822": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d181548f9c42f895ddc4d1c578b9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc18fbf83bf240fa851fd2a291666768": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daab73cd4cd44e8f853567b3adedc650",
            "max": 11153,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a906965159b4ed7ac595072b0caab13",
            "value": 11153
          }
        },
        "cee50c512a2646d2b0edce71af9ff905": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1b42a340f4c4303bc347ee9ee7d2e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd4ffbe076364c7ca5f6fa68396c62ca",
            "placeholder": "​",
            "style": "IPY_MODEL_82f3efc0497c446499fc2ec7419354bc",
            "value": "configuration_phi3.py: 100%"
          }
        },
        "daab73cd4cd44e8f853567b3adedc650": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd4ffbe076364c7ca5f6fa68396c62ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e643706dbdc54dda9b5111d3a6aa528e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f250c285be314b09aafee4a283db20d0",
            "placeholder": "​",
            "style": "IPY_MODEL_c8d181548f9c42f895ddc4d1c578b9ca",
            "value": "modeling_phi3.py: 100%"
          }
        },
        "f250c285be314b09aafee4a283db20d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28e5438dbed4145b91e691469d71a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5da45cbd6f2c4c2aa762ccf5fb974d42",
            "placeholder": "​",
            "style": "IPY_MODEL_cee50c512a2646d2b0edce71af9ff905",
            "value": " 2/2 [00:38&lt;00:00, 18.27s/it]"
          }
        },
        "f405cb8ee1f94e2a8a5e7135bef3b3ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08434042c698451fa8d42152c5ecae11",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fe92f6a73f649a2a92a5b4471ed1789",
            "value": 2
          }
        },
        "fb706afa53924116854c9d168a58a219": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
